{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5347b5de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Demonstration Notebook: GEDI L4A Subsetting on High End Computing Capability (HECC) and AWS Cloud platforms\n",
    "\n",
    "This demonstration of a new capability under development begins after the running the prerequisite and authentication/authorization sections below.\n",
    "\n",
    "## Prerequisite: Install Python packages\n",
    "\n",
    "To run this notebook, we need to install the following Python packages, which might not already be installed in your environment:\n",
    "\n",
    "Required\n",
    "- `requests`\n",
    "- `multiprocessing_logging`\n",
    "- `boto3`\n",
    "- `awscli`\n",
    "\n",
    "Optional, to visualize your result\n",
    "- `geopandas`\n",
    "- `matplotlib`\n",
    "- `folium`\n",
    "- `mapclassify`\n",
    "\n",
    "You may be using a JupyterLab container that has these dependencies already installed.  If not, you may run the following cell to get them installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# python -m venv ./venv/notebook\n",
    "# . ./venv/notebook/bin/activate\n",
    "# python -m pip install --upgrade pip\n",
    "# pip install requests multiprocessing_logging boto3 awscli geopandas matplotlib folium mapclassify\n",
    "conda install -c conda-forge -y --file requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea547ff8-6ca8-4989-a508-c95c3343cbe1",
   "metadata": {},
   "source": [
    "## Authentication and Authorization\n",
    "In the following cell, we set up credentials required to access our AWS and MAAP services.  These settings are used in subsequent cells below.  As described above, eventually we expect that none of these settings will be required and the system will automatically propagate the required credential after an initial login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0572bb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials set up\n"
     ]
    }
   ],
   "source": [
    "# MCP/AWS short term keys are only needed if you want to use your own bucket to stage out the results\n",
    "# from the job. If you use the shared bucket that we provide for your, then no credentials are needed.\n",
    "# out to an S3 bucket.\n",
    "#s3_url = \"\"\n",
    "#aws_access_key_id = \"\"\n",
    "#aws_secret_access_key = \"\"\n",
    "#aws_session_token = \"\"\n",
    "\n",
    "# Configuration for long term access key.  This can be removed now that the ADES is updated to inject the \n",
    "# LTAK into every job's workspace.\n",
    "#aws_config = {\"class\": \"Directory\", \"path\": \"../../.aws\"}\n",
    "\n",
    "# Set MAAP Proxy Granting Ticket (PGT).  This is needed in order to access the input GEDI data files.\n",
    "# This can be removed once MAAP is updated to automatically inject the PGT for use in running jobs.\n",
    "maappgt = \"\"\n",
    "print (\"Credentials set up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c878491",
   "metadata": {},
   "source": [
    "# Subsetting GEDI L4A data on NASA Pleiades High End Computing Capability (HECC) and AWS Cloud platforms\n",
    "\n",
    "In this notebook we demonstrate how algorithms can be run on the High End Computing Capability (HECC) and Cloud platforms without requiring the user to understand the complexities of those platforms.  The same algorithm can be run across the two platforms without modification.  Each platform has its own advantages and drawbacks in terms of cost, throughput, etc., so each project can optimize placement of their algorithms based on their specific needs.  Furthermore, the interface to deploy and execute jobs on these remote processing clusters is compliant with international standards to ensure **portability** and **extensibility** so that configured jobs will work without modification on all supported environments. \n",
    "\n",
    "This notebook demonstrates how to run scalable subsetting of NASA and University of Maryland's [Global Ecosystem Dynamics Investigation (GEDI)](https://gedi.umd.edu/) L4A granules as jobs running across the [NASA Pleiades Supercomputer](https://www.nas.nasa.gov/hecc/resources/pleiades.html) and the [Amazon Web Services (AWS) Cloud](https://aws.amazon.com/).  In the Cloud, we leverage the [AWS Elastic Kubernetes Service (EKS)](https://aws.amazon.com/eks/) to run the computations.  We also leverage software and interfaces developed by the MAAP HEC-AWS project to enable science users to run their notebooks in this way without knowledge of the underlying platforms (HECC or AWS).\n",
    "\n",
    "This is a general capability that can be applied to any science algorithm notebook, but we will use the GEDI L4A subsetting algorithm as an example.  Building and deploying of the algorithms themselves to the remote platforms is not covered in this notebook.  Automation tools exist to make building and deploying of algorithm notebooks easy.  This assumes that an algorithm in a notebook has already been built and deployed to the remote processing cluster.  This notebook demonstrates:\n",
    "1. Execution of a job on remote processing clusters on HECC or AWS\n",
    "1. Monitoring of submitted jobs\n",
    "1. Visualization of job output\n",
    "\n",
    "## OGC standard approach to deploy, run, and monitor jobs on the HECC (Pleaides) and Cloud (AWS) platforms\n",
    "\n",
    "The `ADES_WPST_SQS` interface used in the cells below is a convenience wrapper to simplify deploying algorithms and running them across High End Computing (Pleiades) and Cloud Computing (AWS) platforms.  Read on to learn about the implementation details, but that level of understanding is not necessary since the provided interface makes it entirely transparent to the end user. \n",
    "\n",
    "The current implementation communicates with services running on the underlying compute platforms according to an international standard called [Web Processing Service - Transactional (WPS-T)](https://eoepca.github.io/master-system-design/published/v1.0/#_wps_t_restjson), curated by the [Open Geospatial Consortium (OGC)](https://www.ogc.org/).  The [AWS Simple Queue Service (SQS)](https://aws.amazon.com/sqs/) is used as a messaging broker or intermediary, but that is done in a way that is seamless and transparent so that the complexities of that communication process are completely hidden from the end user. \n",
    "\n",
    "In addition, the output of jobs will be staged out to an [AWS S3](https://aws.amazon.com/s3/) bucket.  We provide a default bucket with credentials pre-configured, so if you choose to use that one then you don't need to provide any configuration.  An endpoint is provide to get the location of job's output so that you can retrieve it.  You do have an option to provide your own S3 bucket for your output, but this \"bring your own bucket\" option does require you to provide AWS access keys and a session token for secure access to these services. You can request these credentials from your cloud provider or system administrator.\n",
    "\n",
    "For now, an additional credential is needed to support access to the GEDI data to be subsetted, but development is underway that will eliminate this requirement and automatically inject this credential into your job execution request.  This credential is required because the input data files needed for the processing are automatically downloaded on the compute platform via an API provided by NASA's [Multi-Mission Algorithm and Analysis Platform (MAAP)](https://scimaap.net/) project.  These are NASA data and require a credential called a Proxy Granting Ticket (PGT) to authenticate access.  The PGT is associated with your MAAP account when you login to the `ops` environment.  This PGT currently needs to be passed as an input to the job, but later this won't be necessary because it will be automatically provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f1c3d-e220-4ec2-a9b5-a34e65e3f15c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Interface to deploy, execute, and monitor algorithms running on the compute platforms\n",
    "In the notebook cells below, we use an interface to easily deploy algorithms, execute jobs, and monitor status on the remote compute platforms.  As described above, the deployment and execution environment on each remote platform is compliant with the Open Geospatial Consortium (OGC) Web Processing Service - Transactional (WPS-T) interface, so this functionality is supported in a manner **compliant with international standards**.  As a result, this approach is **portable** to multiple processing platforms regardless of their underlying computational architecture.  Thus the system is **extensible** to additional remote platforms whether they are on-premises, in a public or private cloud, or at a high end computing center.\n",
    " \n",
    "The `ADES_WPST_SQS` Class, used in the cell below, wraps the various [WPS-T](https://eoepca.github.io/master-system-design/published/v1.0/#_wps_t_restjson) endpoints to perform operations on the selected remote system.  For instance, the `execute` method lets us provide input values and run a job on the remote platform.  Methods (and endpoints) are available to interact with both \"processes\", defined to be an algorithm and associated version, and \"jobs\", defined to be an instantiation of a particular algorithm that includes a set of input parameter values to be applied when the job is run. The following are the types of endpoints avaiable and the `ADES_WPST_SQS` method that wraps each endpoint.\n",
    "\n",
    "- `getLandingPage`: Describe the endpoints available on the platform\n",
    "- `deployProcess`: Deploy a process\n",
    "- `undeployProcess`: Undeploy a process\n",
    "- `getProcesses`: Describe the processes currently deployed on a platform\n",
    "- `getProcessDescription`: Get information about a particular process\n",
    "- `execute`: Execute a job\n",
    "- `dismiss`: Dismiss a job that has been submitted but not yet run\n",
    "- `getJobList`: Describe the jobs that are currently running for a particular process\n",
    "- `getStatus`: Get status and information about a particular job\n",
    "- `getResult`: Get the location where results of a job can be retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe1144",
   "metadata": {},
   "source": [
    "## Connect to distributed processing clusters on NASA High End Computing (Pleiades) and AWS Kubernetes (EKS)\n",
    "\n",
    "For this example, we will connect to two servers running in two different systems: [NASA's Pleiades Supercomputer](https://www.nas.nasa.gov/hecc/resources/pleiades.html) and [AWS/EKS](https://aws.amazon.com/eks/). The services running in both of these platforms are secured behind network firewalls. As described above, we will use the `ADES_WPST_SQS` interface, provided by the MAAP HEC-AWS project to deploy the GEDI Subset algorithm, run jobs, and monitor the execution status of those jobs.  This interface enables us to manage workloads on each secure platform in a way that is seamless and transparent.\n",
    "\n",
    "### Connect to Processing Cluster on NASA High End Computing (Pleiades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33a141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._request_queue_name : ades-pbs-maaphec-dev-002-wpst-request\n",
      "self._reply_queue_name : ades-pbs-maaphec-dev-005-wpst-response\n",
      "Connected to ADES-PBS on NASA Pleiades (HECC)\n"
     ]
    }
   ],
   "source": [
    "from ADES_WPST_SQS import ADES_WPST_SQS\n",
    "\n",
    "# Connect to ADES-PBS on NASA Pleiades (HECC)\n",
    "config_file_pbs = \"./sqsconfig-pbs.py\"\n",
    "wpst_pbs = ADES_WPST_SQS(config_file=config_file_pbs)\n",
    "print(\"Connected to ADES-PBS on NASA Pleiades (HECC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84e029",
   "metadata": {},
   "source": [
    "### Connect to Processing Cluster on AWS Kubernetes (EKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29a2543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._request_queue_name : ades-eks-maaphec-dev-001-wpst-request\n",
      "self._reply_queue_name : ades-eks-maaphec-dev-002-wpst-response\n",
      "Connected to ADES-K8s on AWS EKS (Kubernetes)\n"
     ]
    }
   ],
   "source": [
    "from ADES_WPST_SQS import ADES_WPST_SQS\n",
    "\n",
    "# Connect to ADES-K8s on AWS EKS (Kubernetes)\n",
    "config_file_k8s = \"./sqsconfig-k8s.py\"\n",
    "wpst_eks = ADES_WPST_SQS(config_file=config_file_k8s)\n",
    "print(\"Connected to ADES-K8s on AWS EKS (Kubernetes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47dc612",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Check which WPS-T endpoints are available\n",
    "Let's check the landing pages on our HECC and AWS platforms to confirm our connection has been established successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c432033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_type': 'getLandingPage'}\n",
      "{'QueueUrl': 'https://sqs.us-west-2.amazonaws.com/043575651191/ades-pbs-maaphec-dev-005-wpst-response', 'ResponseMetadata': {'RequestId': 'bfde00d7-a1ad-5dbd-a7e5-5c96fe75146c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'bfde00d7-a1ad-5dbd-a7e5-5c96fe75146c', 'date': 'Wed, 18 Jan 2023 02:46:48 GMT', 'content-type': 'text/xml', 'content-length': '358'}, 'RetryAttempts': 0}}\n",
      "_reply_queue : ades-pbs-maaphec-dev-005-wpst-response\n",
      "message_id : 155647650149547774371021128130113786754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ades_id': 'ades-pbs-dev-jjacob-01',\n",
       " 'api_version': '1.0',\n",
       " 'landingPage': {'links': [{'example': 'curl http://127.0.0.1:5000/',\n",
       "    'href': '/',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getLandingPage',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes',\n",
       "    'href': '/processes',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getProcesses',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl -X POST http://127.0.0.1:5000/processes/proc=https://public-url/to-your-application-descriptor.json',\n",
       "    'href': '/processes',\n",
       "    'parameters': 'proc=<url-to-app.json>',\n",
       "    'payload': '',\n",
       "    'title': 'deployProcess',\n",
       "    'type': 'POST'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>',\n",
       "    'href': '/processes/<procID>',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getProcessDescription',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl -X DELETE http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>',\n",
       "    'href': '/processes/<procID>',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'undeployProcess',\n",
       "    'type': 'DELETE'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs',\n",
       "    'href': '/processes/<procID>/jobs',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getJobList',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl -H \"Content-Type: application/json\" -X POST -d \\'{\"param1\"=\"value1\", \"param2\"=\"value2\"}\\' http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs',\n",
       "    'href': '/processes/<procID>/jobs',\n",
       "    'parameters': 'user=<username>',\n",
       "    'payload': '<workflow-inputs>',\n",
       "    'title': 'execute',\n",
       "    'type': 'POST'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs/<your-job-id-from-getJobList>',\n",
       "    'href': '/processes/<procID>/jobs/<jobID>',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getStatus',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl -X DELETE http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs/<your-job-id-from-getJobList>',\n",
       "    'href': '/processes/<procID>/jobs/<jobID>',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'dismiss',\n",
       "    'type': 'DELETE'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs/<your-job-id-from-getJobList>/result',\n",
       "    'href': '/processes/<procID>/jobs/<jobID>/result',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getResult',\n",
       "    'type': 'GET'}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpst_pbs.getLandingPage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e414ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_type': 'getLandingPage'}\n",
      "{'QueueUrl': 'https://sqs.us-west-2.amazonaws.com/043575651191/ades-eks-maaphec-dev-002-wpst-response', 'ResponseMetadata': {'RequestId': '38da312a-53fe-599a-b44d-6d6b0c19672b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '38da312a-53fe-599a-b44d-6d6b0c19672b', 'date': 'Wed, 18 Jan 2023 02:47:03 GMT', 'content-type': 'text/xml', 'content-length': '358'}, 'RetryAttempts': 0}}\n",
      "_reply_queue : ades-eks-maaphec-dev-002-wpst-response\n",
      "message_id : 281088674356381489982272573544132313613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ades_id': 'maap-hec-ades-k8s',\n",
       " 'api_version': '1.0',\n",
       " 'landingPage': {'links': [{'example': 'curl http://127.0.0.1:5000/',\n",
       "    'href': '/',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getLandingPage',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes',\n",
       "    'href': '/processes',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getProcesses',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl -X POST http://127.0.0.1:5000/processes/proc=https://public-url/to-your-application-descriptor.json',\n",
       "    'href': '/processes',\n",
       "    'parameters': 'proc=<url-to-app.json>',\n",
       "    'payload': '',\n",
       "    'title': 'deployProcess',\n",
       "    'type': 'POST'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>',\n",
       "    'href': '/processes/<procID>',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getProcessDescription',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl -X DELETE http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>',\n",
       "    'href': '/processes/<procID>',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'undeployProcess',\n",
       "    'type': 'DELETE'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs',\n",
       "    'href': '/processes/<procID>/jobs',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getJobList',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl -H \"Content-Type: application/json\" -X POST -d \\'{\"param1\"=\"value1\", \"param2\"=\"value2\"}\\' http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs',\n",
       "    'href': '/processes/<procID>/jobs',\n",
       "    'parameters': 'user=<username>',\n",
       "    'payload': '<workflow-inputs>',\n",
       "    'title': 'execute',\n",
       "    'type': 'POST'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs/<your-job-id-from-getJobList>',\n",
       "    'href': '/processes/<procID>/jobs/<jobID>',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getStatus',\n",
       "    'type': 'GET'},\n",
       "   {'example': 'curl -X DELETE http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs/<your-job-id-from-getJobList>',\n",
       "    'href': '/processes/<procID>/jobs/<jobID>',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'dismiss',\n",
       "    'type': 'DELETE'},\n",
       "   {'example': 'curl http://127.0.0.1:5000/processes/<your-process-id-from-getProcesses>/jobs/<your-job-id-from-getJobList>/result',\n",
       "    'href': '/processes/<procID>/jobs/<jobID>/result',\n",
       "    'parameters': '',\n",
       "    'payload': '',\n",
       "    'title': 'getResult',\n",
       "    'type': 'GET'}]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpst_eks.getLandingPage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f618cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [OPTIONAL] See Present Processess and Jobs Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae652dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpst_eks.fullResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc3a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpst_pbs.fullResult()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524848b",
   "metadata": {},
   "source": [
    "### Set up a GEDI Subset Job\n",
    "\n",
    "In order to submit a job, you need to provide the workflow input values needed.  The inputs get \"spoon-fed\" into the algorithm on the remote platform and the outputs from the job will be staged out to a bucket on AWS S3.  As mentioned above, the `stage_out`section of the inputs is only required if you would like to provide credentials to use your own S3 bucket.  If you use the bucket provided as part of our system, then there is no need to provide the credentials since access to that bucket is pre-configured.\n",
    "\n",
    "The branch is indicated in the process_id in the cells below.  You can run either the `hec` or `main` branch. The hec branch supports caching of the\n",
    "GEDI files on ADES-PBS.  The main branch does not support caching of the GEDI files.  One just one of the two cells below, depending on which branch you\n",
    "want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb11cef-1975-449d-a278-75b052c20c8f",
   "metadata": {},
   "source": [
    "#### Example main branch job\n",
    "\n",
    "The `main` branch does not support caching and stages in only the GeoJSON file\n",
    "that describes the area of interest (AOI).  The GEDI files that intersect the\n",
    "AOI are searched for and localized in the \"process\" step (not in \"stage-in\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The branch is indicated in the process_id below.\n",
    "# The hec branch supports caching of GEDI files on ADES-PBS.\n",
    "# The main branch does not support caching of GEDI files.\n",
    "process_id = \"jplzhan.gedi-subset.main-1.0.0\"\n",
    "job_inputs = {\n",
    "#   \"stage_out\": {\n",
    "#      \"s3_url\": s3_url,\n",
    "#      \"aws_access_key_id\": aws_access_key_id,\n",
    "#      \"aws_secret_access_key\": aws_secret_access_key,\n",
    "#      \"aws_session_token\": aws_session_token,\n",
    "#      \"region\": \"us-west-2\"\n",
    "#      \"aws_config\": aws_config,      \n",
    "#I   },\n",
    "   \"parameters\": {\n",
    "      \"aoi\": {\n",
    "         \"url\": \"https://github.com/wmgeolab/geoBoundaries/raw/9f8c9e0f3aa13c5d07efaf10a829e3be024973fa/releaseData/gbOpen/GAB/ADM0/geoBoundaries-GAB-ADM0.geojson\"\n",
    "      },\n",
    "      \"columns\": \"agbd, agbd_se, l2_quality_flag, l4_quality_flag, sensitivity, sensitivity_a2, lon_lowestmode, lat_lowestmode\",\n",
    "      \"query\": \"l2_quality_flag == 1 and l4_quality_flag == 1 and sensitivity > 0.95 and sensitivity_a2 > 0.95\",\n",
    "#      \"limit\": 10000,\n",
    "#      \"limit\": 100,\n",
    "#      \"limit\": 10,\n",
    "      \"limit\": 2,\n",
    "      \"maappgt\": maappgt\n",
    "   }\n",
    "}\n",
    "print(job_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e69c8-b190-4046-b63a-e1d41eb4f1dd",
   "metadata": {},
   "source": [
    "#### Example hec branch job\n",
    "\n",
    "The `hec` branch supports caching on ADES-PBS and localizes the GEDI input \n",
    "files during the \"stage_in\" step.  The URLs for the GEDI files must be specified\n",
    "as job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd1f1b01-b621-48f9-b078-19f22b20d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameters': {'aoi': {'url': 'https://github.com/wmgeolab/geoBoundaries/raw/9f8c9e0f3aa13c5d07efaf10a829e3be024973fa/releaseData/gbOpen/GAB/ADM0/geoBoundaries-GAB-ADM0.geojson'}, 'granules': {'url': ['https://data.ornldaac.earthdata.nasa.gov/protected/gedi/GEDI_L4A_AGB_Density_V2_1/data/GEDI04_A_2019146134206_O02558_01_T05641_02_002_02_V002.h5', 'https://data.ornldaac.earthdata.nasa.gov/protected/gedi/GEDI_L4A_AGB_Density_V2_1/data/GEDI04_A_2019160192444_O02779_04_T02282_02_002_02_V002.h5'], 'maap_pgt': ''}, 'columns': 'agbd, agbd_se, l2_quality_flag, l4_quality_flag, sensitivity, geolocation/sensitivity_a2', 'query': 'l2_quality_flag == 1 and l4_quality_flag == 1 and sensitivity > 0.95 and `geolocation/sensitivity_a2` > 0.95', 'lat': 'lat_lowestmode', 'lon': 'lon_lowestmode', 'beams': 'all'}}\n"
     ]
    }
   ],
   "source": [
    "# The branch is indicated in the process_id below.\n",
    "# The hec branch supports caching of GEDI files on ADES-PBS.\n",
    "# The main branch does not support caching of GEDI files.\n",
    "process_id = \"jplzhan.gedi-subset.hec-1.0.0\"\n",
    "job_inputs = {\n",
    "#   \"stage_out\": {\n",
    "#      \"s3_url\": s3_url,\n",
    "#      \"aws_access_key_id\": aws_access_key_id,\n",
    "#      \"aws_secret_access_key\": aws_secret_access_key,\n",
    "#      \"aws_session_token\": aws_session_token,\n",
    "#      \"region\": \"us-west-2\"\n",
    "#      \"aws_config\": aws_config,    \n",
    "#    },\n",
    "    \"parameters\": {\n",
    "        \"aoi\": {\n",
    "            \"url\": \"https://github.com/wmgeolab/geoBoundaries/raw/9f8c9e0f3aa13c5d07efaf10a829e3be024973fa/releaseData/gbOpen/GAB/ADM0/geoBoundaries-GAB-ADM0.geojson\"\n",
    "        },\n",
    "        \"granules\": {\n",
    "            \"url\": [\n",
    "                \"https://data.ornldaac.earthdata.nasa.gov/protected/gedi/GEDI_L4A_AGB_Density_V2_1/data/GEDI04_A_2019146134206_O02558_01_T05641_02_002_02_V002.h5\",\n",
    "                \"https://data.ornldaac.earthdata.nasa.gov/protected/gedi/GEDI_L4A_AGB_Density_V2_1/data/GEDI04_A_2019160192444_O02779_04_T02282_02_002_02_V002.h5\"\n",
    "            ],\n",
    "            \"maap_pgt\": maappgt\n",
    "        },\n",
    "        \"columns\": \"agbd, agbd_se, l2_quality_flag, l4_quality_flag, sensitivity, geolocation/sensitivity_a2\",\n",
    "        \"query\": \"l2_quality_flag == 1 and l4_quality_flag == 1 and sensitivity > 0.95 and `geolocation/sensitivity_a2` > 0.95\",\n",
    "        \"lat\": \"lat_lowestmode\",\n",
    "        \"lon\": \"lon_lowestmode\",\n",
    "        \"beams\": \"all\"\n",
    "    }\n",
    "}\n",
    "print(job_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904abb3e",
   "metadata": {},
   "source": [
    "### Submit a GEDI Subset job to Pleiades\n",
    "We will use the job inputs defined above and submit the job to run on the remote Pleiades supercomputer.  When a job is run, it is automatically assigned a unique identifier that can be used in subsequent calls to check the status of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c247e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jplzhan.gedi-subset.hec-1.0.0\n",
      "{\n",
      "  \"parameters\": {\n",
      "    \"aoi\": {\n",
      "      \"url\": \"https://github.com/wmgeolab/geoBoundaries/raw/9f8c9e0f3aa13c5d07efaf10a829e3be024973fa/releaseData/gbOpen/GAB/ADM0/geoBoundaries-GAB-ADM0.geojson\"\n",
      "    },\n",
      "    \"granules\": {\n",
      "      \"url\": [\n",
      "        \"https://data.ornldaac.earthdata.nasa.gov/protected/gedi/GEDI_L4A_AGB_Density_V2_1/data/GEDI04_A_2019146134206_O02558_01_T05641_02_002_02_V002.h5\",\n",
      "        \"https://data.ornldaac.earthdata.nasa.gov/protected/gedi/GEDI_L4A_AGB_Density_V2_1/data/GEDI04_A_2019160192444_O02779_04_T02282_02_002_02_V002.h5\"\n",
      "      ],\n",
      "      \"maap_pgt\": \"\"\n",
      "    },\n",
      "    \"columns\": \"agbd, agbd_se, l2_quality_flag, l4_quality_flag, sensitivity, geolocation/sensitivity_a2\",\n",
      "    \"query\": \"l2_quality_flag == 1 and l4_quality_flag == 1 and sensitivity > 0.95 and `geolocation/sensitivity_a2` > 0.95\",\n",
      "    \"lat\": \"lat_lowestmode\",\n",
      "    \"lon\": \"lon_lowestmode\",\n",
      "    \"beams\": \"all\"\n",
      "  }\n",
      "}\n",
      "{'QueueUrl': 'https://sqs.us-west-2.amazonaws.com/043575651191/ades-pbs-maaphec-dev-005-wpst-response', 'ResponseMetadata': {'RequestId': '6c6b2db4-a46d-5db8-955f-71f5c4758256', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6c6b2db4-a46d-5db8-955f-71f5c4758256', 'date': 'Wed, 18 Jan 2023 02:47:52 GMT', 'content-type': 'text/xml', 'content-length': '358'}, 'RetryAttempts': 0}}\n",
      "_reply_queue : ades-pbs-maaphec-dev-005-wpst-response\n",
      "message_id : 240339636829054061112969375787049458694\n",
      "{\n",
      "  \"ades_id\": \"ades-pbs-dev-jjacob-01\",\n",
      "  \"api_version\": \"1.0\",\n",
      "  \"jobID\": \"jplzhan.gedi-subset.hec-1.0.0-c2e5124ab8fc4190c0aa60af5106ede4e57e4317\",\n",
      "  \"status\": \"accepted\"\n",
      "}\n",
      "jplzhan.gedi-subset.hec-1.0.0-c2e5124ab8fc4190c0aa60af5106ede4e57e4317\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "job_id_pbs = wpst_pbs.execute(process_id, job_inputs)\n",
    "print(job_id_pbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47b882",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check Status of the Job Submitted in Pleiades\n",
    "Check the status of the submitted job by using the job identifier returned when the job was submitted for execution. Run this repeatedly until you see the status is `successful`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def job_status_for(process_id:str, job_id: str) -> str:\n",
    "    response = wpst_pbs.getStatus(process_id, job_id)\n",
    "    \n",
    "    print(json.dumps(response, indent=2))\n",
    "    return response[\"statusInfo\"][\"status\"]\n",
    "\n",
    "job_status = job_status_for(process_id, job_id_pbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75dc322",
   "metadata": {},
   "source": [
    "### Submit a Job to EKS\n",
    "Next, we will submit the same job to a Kubernetes cluster running in the AWS Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242dc439",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_k8s = wpst_eks.execute(process_id, job_inputs)\n",
    "print(job_id_k8s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86171e",
   "metadata": {},
   "source": [
    "### Verify Job Status\n",
    "Check the status of the submitted job by using the job identifier returned when the job was submitted for execution.  Run this repeatedly until you the `status` is `successful`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39573b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def job_status_for(process_id:str, job_id: str) -> str:\n",
    "    response = wpst_eks.getStatus(process_id, job_id)\n",
    "    \n",
    "    print(json.dumps(response, indent=2))\n",
    "    return response[\"statusInfo\"][\"status\"]\n",
    "    \n",
    "job_status = job_status_for(process_id, job_id_k8s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd36ff42",
   "metadata": {},
   "source": [
    "### Get location of job results\n",
    "\n",
    "If the job has completed successfully, you can get the location on S3 where the job's output was staged for you to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_result = wpst_pbs.getResult(process_id, job_id_pbs)\n",
    "print(job_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa5bc3",
   "metadata": {},
   "source": [
    "## Visually Verify the Results\n",
    "\n",
    "### Localize the output file\n",
    "\n",
    "Use the AWS CLI to download the output file from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e35bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://maap-hec-ades-out-dev/jplzhan/gedi_subset/jplzhan.gedi-subset.main-1.0.0-6b86b462751c7983d3c2fb01141e7aa45d667e5d/output/gedi_subset.gpkg gedi_subset.gpkg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686520a7",
   "metadata": {},
   "source": [
    "### Static visualization with geopandas\n",
    "If you installed the `geopandas` and `matplotlib` Python packages, you can visually verify the output file by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b146a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import geopandas as gpd\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    print(\n",
    "        \"If you wish to visually verify your output file, \"\n",
    "        \"you must install the `geopandas` and `matplotlib` packages.\"\n",
    "    )\n",
    "else:\n",
    "    gedi_gdf = gpd.read_file(\"gedi_subset.gpkg\")\n",
    "    gedi_gdf = gedi_gdf.sample(n=1000)\n",
    "    # gedi_gdf = gpd.read_file(\"gedi_subset.gpkg\", rows=1000)\n",
    "    print(\"done reading\")\n",
    "    agbd_colors = plt.cm.get_cmap(\"viridis_r\")\n",
    "    gedi_gdf.plot(column=\"agbd\", cmap=agbd_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ddff9",
   "metadata": {},
   "source": [
    "### Dynamic visualization with Folium/Leaflet\n",
    "\n",
    "Folium provides a more interactive visualization experience that lets you pan and zoom with the output data overlaid on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f7e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fiona geopandas folium matplotlib mapclassify\n",
    "import folium\n",
    "m = gedi_gdf.explore(\n",
    "     #m=m, # pass the map object\n",
    "     color=\"red\", # use red color on all points\n",
    "     marker_kwds=dict(radius=5, fill=True), # make marker radius 10px with fill\n",
    "     tooltip=\"filename\", # show \"name\" column in the tooltip\n",
    "     tooltip_kwds=dict(labels=False), # do not show column label in the tooltip\n",
    "     name=\"gedi_subset\" # name of the layer in the map\n",
    ")\n",
    "\n",
    "folium.TileLayer('Stamen Toner', control=True).add_to(m)  # use folium to add alternative tiles\n",
    "folium.LayerControl().add_to(m)  # use folium to add layer control\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c32118f",
   "metadata": {},
   "source": [
    "### Direct view\n",
    "\n",
    "The data can also be viewed directly in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dda7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gedi_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
